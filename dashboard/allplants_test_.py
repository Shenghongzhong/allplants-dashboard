# -*- coding: utf-8 -*-
"""allplants_test_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12bgEoJq2t6Af4STX4RQyP-uekX1NWRMU
"""

# Jovian Commit Essentials
# Please retain and execute this cell without modifying the contents for `jovian.commit` to work


"""# Allplants Test Interview

![](https://pbs.twimg.com/media/Edm7jmrXgAIKgG2?format=png&name=medium)

## How to run the code

This tutorial is an executable [Jupyter notebook](https://jupyter.org) hosted on [Jovian](https://www.jovian.ai). You can _run_ this tutorial and experiment with the code examples in a couple of ways: *using free online resources* (recommended) or *on your computer*.

#### Option 1: Running using free online resources (1-click, recommended)

The easiest way to start executing the code is to click the **Run** button at the top of this page and select **Run on Binder**. You can also select "Run on Colab" or "Run on Kaggle", but you'll need to create an account on [Google Colab](https://colab.research.google.com) or [Kaggle](https://kaggle.com) to use these platforms.


#### Option 2: Running on your computer locally

To run the code on your computer locally, you'll need to set up [Python](https://www.python.org), download the notebook and install the required libraries. We recommend using the [Conda](https://docs.conda.io/projects/conda/en/latest/user-guide/install/) distribution of Python. Click the **Run** button at the top of this page, select the **Run Locally** option, and follow the instructions.

>  **Jupyter Notebooks**: This tutorial is a [Jupyter notebook](https://jupyter.org) - a document made of _cells_. Each cell can contain code written in Python or explanations in plain English. You can execute code cells and view the results, e.g., numbers, messages, graphs, tables, files, etc., instantly within the notebook. Jupyter is a powerful platform for experimentation and analysis. Don't be afraid to mess around with the code & break things - you'll learn a lot by encountering and fixing errors. You can use the "Kernel > Restart & Clear Output" menu option to clear all outputs and start again from the top.

### Orders and Order Items 

The 'Orders' and 'Orders_items' tabs contain two datasets:

- Orders: 
>>`order_id`
>>
>>`placed_at` (the date the customer paid for the order)
>>
>>`customer_id`
>>
>> `order_number` (so for each customer, is this their 1st, 2nd or 100th order?)
>>
>> `is_trial` (if the order was a smaller trial order)
>>
>> `gross_revenue` (so the total value of the order, ignoring any discount that was applied to it)

- Order_items: 
>>`order_id` (the order that the item belongs to)
>>
>>`sku_code` (the name of the product)
>>
>> `product_type` (whether the product is a meal, treat, breakfast, smoothie, side or other)
>>
>>`item_quantity` (the number of that product present in that order)

The data is a random sample of orders from 3rd Aug 20 to 4th Oct 20

# Questions

1. How much revenue came from 1st time orders only each month?
2. Which customer (or customer id!) placed the most orders in this time period, and how many orders did they place? (3rd Aug 20 to 4th Oct 20)
3. Making use of both datasets, what was the dish that this same customer ordered the most? And how many times did they order it?

4. The food development team have asked for your help in deciding what new dish(es) they should create next.
>
>Use the data available and any small pieces of analysis you think appropriate to support a few recommendations for the food team. It's completely fine to guess at what some of the `SKU codes` actually are where it's unclear. You may also describe the analysis you would do, given more time / data. Lay out your recommendations below, and we'll use this as a starter discussion topic in the next round!
Please show any working where you can.

5. Imagine we wanted to launch 3 SKUs (SKUs = products: e.g., a croissant, pain au chocolat & pain aux raisins) in a new "pastries" range in October 2020.
>>Based on the data available, plus your own sensible assumptions:
>>>
>>>a) how many do you think we'd sell on a weekly basis?
>>>
>>>b) what price point do you think we should price them at? And what would be the main considerations / bits of information you'd want to inform this decision?
Please show any working/evidence to support assumptions where you can.

# Uploading Data

> `pip` stands for `Python Install Packages`
"""

# Import Packages
import ssl
import pandas as pd
import numpy as np
import plotly.express as px
from datetime import datetime
from urllib.request import urlretrieve

"""I created two gists for storing data so we can save the hustles and do analysis straightforwardly."""

# Download data
ssl._create_default_https_context = ssl._create_unverified_context
orders_url = 'https://gist.githubusercontent.com/Shenghongzhong/a70c0c8fffb44a37f31649a75152c0a5/raw/cd5c5830f1052c721e709ef9687701f266648128/allplants-orders'
order_items_url = 'https://gist.githubusercontent.com/Shenghongzhong/65d238836ed7e04624e1e527397c2fdb/raw/c50aa269338f0c9e08d0d8fa68d8785800f26262/allplants_order_items'

urlretrieve(orders_url, 'orders.csv')
urlretrieve(order_items_url, 'orders_items.csv')

# Load data into pandas dataframe ojects
order_infor = pd.read_csv('orders.csv')
order_infor.drop('Unnamed: 0',axis=1,inplace=True)

order_items = pd.read_csv('orders_items.csv')

# Convert column names to lower cases
# Replace blank spaces with underscore
order_infor.columns =order_infor.columns.str.replace(' ','_').str.lower()
order_items.columns =order_items.columns.str.replace(' ','_').str.lower()

"""## Understanding data

### Order information table

For the order table, columns are as follows:

- `order_infor`
>>`order_id`
>>
>>`placed_at` (the date the customer paid for the order)
>>
>>`customer_id`
>>
>> `order_number` (for each customer, is this their 1st, 2nd or 100th order?)
>>
>> `is_trial` (if the order was a smaller trial order)
>>
>> `gross_revenue` (so the total value of the order, ignoring any discount that was applied to it)
"""

# First glance at the 
order_infor.head()

#rows, cols = order_infor.shape
#print('For order information table, we have {} rows, {} columns'.format(rows,cols))

"""### Order Items Table

- `Order_items`: 
>>`order_id` (the order that the item belongs to)
>>
>>`sku_code` (the name of the product)
>>
>> `product_type` (whether the product is a meal, treat, breakfast, smoothie, side or other)
>>
>>`item_quantity` (the number of that product present in that order)
"""

order_items.head()

#rows, cols = order_items.shape
#print('For order items table, we have {} rows, {} columns'.format(rows,cols))

"""### Working with dates"""

# Convert date to datetime data type
order_infor['placed_date'] = pd.to_datetime(order_infor['placed_date'])
order_infor['year'] = pd.DatetimeIndex(order_infor.placed_date).year
order_infor['month'] = pd.DatetimeIndex(order_infor.placed_date).month
order_infor['day'] = pd.DatetimeIndex(order_infor.placed_date).day
order_infor['weekday'] = pd.DatetimeIndex(order_infor.placed_date).weekday

"""### Helper functions"""

def make_hor_bar(data_frame,x_label,y_label,hover_data,title,x_title,y_title,template,y_is_category=None):
  """
  dataframe, x, y, hover_data, the chart title, title(x axis),title(y axis), template, y is category or numerical
  """
  fig = px.bar(data_frame=data_frame, 
             x=x_label,
             y=y_label,
             hover_data =hover_data,
             orientation='h')
  
  # Y axis is category
  if y_is_category == True:
    fig.update_yaxes(type='category')
  # Template theme
  if template =='dark':
    fig.update_layout(template='plotly_dark',
                  title =title,
                  xaxis_title = x_title,
                  yaxis_title = y_title
                  )
  else:
    fig.update_layout(
                  title =title,
                  xaxis_title = x_title,
                  yaxis_title = y_title
                  )

  return fig


# For question 5
def compare_product(product):
  """
  Reduce the repeated codes to get the total sales of specific product;
  Input: the product name you want to check
  Output: the total number of sales
  """
  nums_sales = order_items[order_items['sku_code']==product]['sku_code'].value_counts().iloc[0]
  return nums_sales

"""# Answering Questions

#### 1. How much revenue came from 1st time orders only each month?




"""

# See range of order number
order_number_list = sorted(order_infor.order_number.unique())

#print(" For order numbers, we have the minimum order number of {}, whereas the maximum is {}".format(order_number_list[0],order_number_list[-1]))


# Filter out the first order
first_order = order_infor[order_infor['order_number'] == 1]

# Group By to see monthly revenue
revenue_each_month = first_order.groupby(['month'])[['gross_revenue']].sum().reset_index().sort_values('gross_revenue',ascending=True)
revenue_each_month ['%'] = revenue_each_month['gross_revenue']/order_infor['gross_revenue'].sum()


revenue_each_month.style.format({'gross_revenue': "{:.2f}",'%': "{:.2%}"})

# See Helper Functions Section
question_fig_1 = make_hor_bar(revenue_each_month,
                   'gross_revenue',
                   'month',
                   ['month','gross_revenue','%'],
                   'Total Revenues from 1st Order Each Month',
                   'Gross Revenue',
                   'Months',
                   None,
                   y_is_category=True)

#fig.show()

revenue_each_month_avg = revenue_each_month['gross_revenue'].mean()

"""### Analysis
Each month, we had approximately £45K from the first time order from 3rd Aug to 4th Oct. However, we had the highest number of first time orders in Sep 2020, in which we generated £75.67K, accounting for 14.84% of the total revenue given the dataset. We can investigate reasons why there was an increase. I reckoned maybe Allplants implemented new advertising strategies that brought more new customers.

For the following activities, we should focus on which platforms brought the most customers and what campaigns we used to motivate customers to sign up and make the purchase decision.

Secondly, we need to look at supply and delivery. We can look at the areas if we have problems with the supply and delivery, the number of products done by the food development each day, week.

Thirdly, We can also look at the customer experience by getting data about the conversation rate from 3rd Aug to 4th Oct, the number of the second order from the first order, etc.

#### 2. Which customer (or customer id!) placed the most orders in this time period, and how many orders did they place? (3rd Aug 20 to 4th Oct 20)
"""

# Count orders by customer
# Prepare for data viz
top_ten_customers = order_infor['customer_id'].value_counts().reset_index().rename(columns={'index':'customer_id','customer_id':'counts'}).head(10)
customers = ['Customer 10','Customer 9','Customer 8','Customer 7','Customer 6','Customer 5','Customer 4','Customer 3','Customer 2','Customer 1']
top_ten_customers=top_ten_customers.sort_values('counts',ascending=True)
top_ten_customers['categories'] = customers
top_ten_customers.set_index('categories',inplace=True)

# Plot the top 10 customers who ordered the most
question_fig_2 = make_hor_bar(top_ten_customers,
                   'counts',
                   top_ten_customers.index,
                   ['customer_id','counts'],
                   'Total order number by customer',
                   'Order Numbers',
                   'Customers',
                   None,
                   y_is_category=True)

#fig.show()

max_order_mvp = order_infor[order_infor['customer_id']==55873]['order_number'].max()

"""#### Analysis

To answer the question, the customer id (55873) ordered the most given the time. Given the sample dataset, the total number of customers placed was 11 orders. Presumably, the customer is a regular customer. The customer had purchased products at Allplants for the 30th time, from the 3rd of August to the 4th of October.

For the next action, we may need to investigate the types of orders the customer id(55873) ordered the most, and maybe we should send discounts or some forms of coupon or referrals. The customer is likely to enjoy the service provided by Allplants.

I'd like to ask questions about the behaviours of the customer. Could we create more customers like the customer id (55873)? Why did top 5 customers order so many products from Allplants, apart from the quality and brands? Did they order similar products? If we can get more data about these groups of people, could we retarget similar customer prospects online when doing digital marketing?


---

#### 2. Making use of both datasets, what was the dish that this same customer ordered the most? And how many times did they order it?
"""

total_types = order_items.sku_code.nunique()

#print('There are {} types of dish in total'.format(total_types))

"""In the dataset, the `sku_code` of `BOLOGNESE_1` is the most popular dish without considering a specific customer. 

By knowing the most popular product, we know the benchmark of the popular product in the whole dataset.
"""

order_items['sku_code'].value_counts().reset_index().rename(columns={'index':'sku_code','sku_code':'counts'})

# Merge 2 table into 1 table
merged_df = order_infor.merge(order_items,on='order_id')
# Assign the customer who ordered the most
most_customer = merged_df[merged_df['customer_id'] == 55873]

top_ten_dishes = most_customer['sku_code'].value_counts().reset_index().rename(columns={'index':'sku_code','sku_code':'counts'})
top_ten_dishes =top_ten_dishes.sort_values('counts',ascending=True)

# Visualize the data
question_fig_3 = make_hor_bar(
                    top_ten_dishes,
                    'counts','sku_code',
                    ['sku_code','counts'],
                    'Total Number of Dishes Ordered by Customer(55873)',
                    'The Number of Dishes',
                    'Dishes',
                    None,
                    y_is_category=True)

#fig.show()

"""#### Analysis

The customer(55873) ordered serveral products the most such as **CARBONARA_2**, **SHEPHERD_2**,	**BANOFFEE_1**,**CRUMBLE_1**,**ORZO_2**. The number of theses products is all 9.

Having done some basic google, this was what I found at the website and made a slide together

![](https://i.imgur.com/Eofw51x.png)

#### 3. The food development team have asked for your help in deciding what new dish(es) they should create next.

- Use the data available and any small pieces of analysis you think appropriate to support a few recommendations for the food team. 
- It's completely fine to guess at what some of the `SKU codes` actually are where it's unclear. You may also describe the analysis you would do, given more time / data. 
- Lay out your recommendations below, and we'll use this as a starter discussion topic in the next round!

Please show any working where you can.
"""

# Prepare data for plotting
product_types_df = order_items.groupby(['product_type'])[['item_quantity']].sum().sort_values('item_quantity',ascending=False).reset_index() 
output_df = product_types_df.sort_values('item_quantity',ascending=True)
product_types_df

# Plot Bar Chart
question_fig_3_a = make_hor_bar(
                                output_df,
                                'item_quantity',
                                'product_type',
                                ['product_type','item_quantity'],
                                'Total Number of Product Type',
                                'The Number of sku code',
                                'sku_code',
                                None,
                                y_is_category=True)
#fig.show()

"""We know the `MEAL` is our key product line many customers purchased from the chart above. It is also not surprising to see `BREAKFAST` come after. It's fascinating to see `PIZZA` wasn't on the top 3, and I wondered if customers prefer to buy pizza from supermarkets because the pizza price is cheaper or more convenient

Another possible reason could be many customers are working professionals, so they're likely to use kitchens at work to cook these pre-made meals. Meals are more manageable comparing to pizza, in my opinion.

We would like to look into details about specific products within these categories (`MEAL`, `BREAKFAST`, `TREAT` etc.)
"""

# Group by Product Type, Specific Product
sku_code_df= order_items.groupby(['product_type','sku_code'])[['item_quantity']].sum().sort_values('item_quantity',ascending=False).reset_index()
order_items.groupby(['product_type','sku_code'])[['item_quantity']].sum().sort_values('item_quantity',ascending=False)

# Create Pivot Table
product_pivot_df = sku_code_df.pivot('sku_code','product_type','item_quantity')
product_pivot_df.fillna('0',inplace=True)

"""Due to the issue of Google Colab, pandas can't highlight the max values in the table below. So I would recommend that we use excel or other tools to do analysis."""

# Commented out IPython magic to ensure Python compatibility.
# %load_ext google.colab.data_table
product_pivot_df.style.highlight_max(axis=0).set_properties( **{'color': 'red'})
#product_pivot_df.style.highlight_max()

"""The Pivot Table didn't tell us too much information. However, as an outsider, I can tell Allplants focuses on developing meal first. I was wondering if Allplants consideres expanding product territory?

I was interested to see how other product structure at Allplants related to the order data.
"""

# Exclude Meal to see componetns of other product
no_meal_sku_code_df = sku_code_df[sku_code_df['product_type'] != 'MEAL']

question_fig_3_b = px.bar(data_frame=no_meal_sku_code_df , 
             x='product_type',
             y='item_quantity',
             hover_data =['product_type','sku_code','item_quantity'],
             color='sku_code')


question_fig_3_b.update_layout(
                  title ='Total number of dishes ordered by customer(55873)',
                  xaxis_title = 'the Numbers of dishs',
                  yaxis_title = 'Dishes'
                  )
#fig.show()

"""### Analysis

The product type of `MEAL` was sold the most, comparing with other product types. We have to look at other product types separately. 

As shown in the bar chart, the meal had been sold for **56K **given the time. Of which, the popular dishes were `BOLOGNESE_1`, `PROTEIN_1`, `KATSU_2`, `PROTEIN_2`, `PADTHAI_2`. `BOLOGNESE_1` is the most popular. Also, we can guess customers also like something with rich protein, other popular cuisines such as Japanese and Thai food. In all, the recommended cuisines could be from Asia, such as Japanese-food curry, Thai food， Vietnamese food,  if the food development team considers developing new cuisines. However, since the data told us these were popular products, it's good to prepare ingredients for cooking these types of food.

Other than that, we found out that the number of `BERRY_1` was old the most, of 703, followed by the `MANGO_1` for the `BREAKFAST`. We recommend that we can create more sour fruit-based breafast food. 

As for the `TREAT`,  the top 3 products were `FOUNDANT`, `BANOFFEE` and `CRUMBLE`. They are quite common treats. We can continue these 3 types of products and make sure our supply is sufficient.

#### 5. Imagine we wanted to launch 3 SKUs (SKUs = products: e.g., a croissant, pain au chocolat & pain aux raisins) in a new "pastries" range in October 2020.
>>Based on the data available, plus your own sensible assumptions:
>>>
>>>a) how many do you think we'd sell on a weekly basis?
>>>
>>>b) what price point do you think we should price them at? And what would be the main considerations / bits of information you'd want to inform this decision?
Please show any working/evidence to support assumptions where you can.

My first thought would be to frame this question in a slightly different way: 

What's the weekly average sales did we have for one unit of `sku_code` ?

Because my principle is that we start from stupidly easy questions to solve any complicated problems. Gradually, we can build upon that direction.

*The average is the sample mean rather than the population mean

$$\text{Weekly Average Sales} = \frac{\text{Total Number of sku_code}}{\text{Total Number of Weeks}}$$
"""

# Sum up sku_code
nums_sku = order_items['sku_code'].value_counts().sum()

# Subtract two dates
delta = order_infor['placed_date'].max()- order_infor['placed_date'].min()
nums_weeks = delta.days/7

weekly_average_sku = nums_sku/nums_weeks
#print('Every week there is the average of sales of sku_code is {:.2f} units"'.format(weekly_average_sku))

"""
We know we have the average sales of 6,9K units of `sku_code`. That's our benchmark without considering any other factors such as product types, tastes, nutritions etc. 

Since Allplants is doing food business, we would need to consider the similarities of tastes of products we're going to launch, if we would like to make a good prediction for the potential sales on a weekly basis and also recommending the price range for the new products.

Let's have a look at products we're launching. They are croissant, pain au chocolat & pain aux raisins.


![](https://i.imgur.com/308jmzu.png)


Personally, I'd think I should compare the products to `BREAKFAST` or `TREAT`. 

Let's look at products under these 2 product types"""

# View the table of 2 BREAKFAST & TREAT
order_items[(order_items['product_type']=='BREAKFAST') | (order_items['product_type']=='TREAT')]

# View BREAKFAST by product
order_items[order_items['product_type']=='BREAKFAST']['sku_code'].unique()

"""![](https://i.imgur.com/yotnI0D.png)"""

# View TREAT by product
order_items[order_items['product_type']=='TREAT']['sku_code'].unique()

"""![](https://i.imgur.com/iaLfQiD.png)"""

# View SIDE by product
order_items[order_items['product_type']=='SIDE']['sku_code'].unique()

"""Having looked at these products, I would select `BANOFFEE_1`, `FONDANT_1`, `TR_TIRAMISU_1` regarding my personal tastes. They're approximately close to the new products we're going to launch. However, the breakfast are more smoothie-base food. 

In terms of the number of sales, we can see the weekly average sales of these prdocuts (`BANOFFEE_1`, `FONDANT_1`, `TR_TIRAMISU_1`)
"""

# List prodcuts to compare
product_list = ['BANOFFEE_1', 'FONDANT_1', 'TR_TIRAMISU_1']
# List Comprehension
results_list = [compare_product(product) for product in product_list]
results_df = pd.DataFrame(results_list,index=product_list).rename(columns={0:'Sales'}).sort_values('Sales',ascending=True)

results_df['Weekly Average Sales'] = results_df['Sales']/nums_weeks
# Visualize results

question_fig_4 = make_hor_bar(
                        results_df,
                        'Weekly Average Sales',
                        results_df.index,
                        ['Sales','Weekly Average Sales',results_df.index],
                        "Weekly Average Sales by Similar Products (In Treat",'Total Sales',
                        'Products',
                        None,
                        y_is_category=True)

# View similar products by Sales
results_df.sort_values('Sales',ascending=False).style.format({'Weekly Average Sales': "{:.2f}"})

"""From this chart, we can see `FONDANT_1` has the highest weekly average sales of 82 units, comparing with other two products. 


The `TR_TIRAMISU_1` has been sold at 1.9 units. So I'd say the products we're going launch could be sold from 1.9 units to 82 units per week. 

In terms of pricing, we can have a look at the revenue and the price per item.

$$ \text{Profits Per Unit}= \frac{\text{Gross Revenue}}{\text{Total Number of Items}*\text{Sales}}$$
"""

# revenues
#revenue_product = merged_df.groupby('sku_code')['gross_revenue','item_quantity'].sum()
#target_products_df = revenue_product.loc[product_list]
#revenue_df = results_df.join(target_products_df,on=results_df.index)
#revenue_df['Profits Per Unit'] = revenue_df['gross_revenue']/(revenue_df['Sales']*revenue_df['Sales'])
#revenue_df

"""Since we only have data about revenue, we can get a figure by subtracting gross revenue from the product of the total sales multiplying the total items. However, I couldn't tell what the figure was, but my guess would be profit. I could be wrong because prices and costs are two unknown variables. So I would need more information and data about price and cost to give a better conclusion.

Yet, I was confused by seeing `BANOFFEE_1` and `FONDANT_1` have really low numbers of 0.10 and 0.08, respectively. Are they really that cheap, and the profit margins are so low for each item sold at Allplants.

In Sainsbury, Croissant is sold at 80p [Link](https://www.sainsburys.co.uk/gol-ui/product/sainsburys-all-butter-croissant?utm_medium=cpc&catalogId=10241&productId=652070&utm_campaign=11354430451&storeId=10151&gclid=CjwKCAjw2P-KBhByEiwADBYWCrrCdCEF-c_j8MK1EPi0nCaI5kdfTFUcoCqNl5ShLt2sC-Bcxc6UlxoCQ1UQAvD_BwE&langId=44&utm_source=Google&krypto=lFV9Qo%2BP4yp%2FtiodxZKeItgXe%2Bn0A05JW7TjP99KYfPZ0jZ5QI6EsOo3y3vxiC55wjd6hqV7PgsivsIwQV%2F00jpXCaFa0FS9mNsA71yq5B5H%2Fdwp0u7DQ2arvwBo%2ByVIO%2FiSbQR8sON3CwDbvAS7tfM0YXLVZpk5pBeBr8n47rSXUVfm%2Fap0l5qDr6lSfLjYwXh99OJTqwOwaEWcEUrEK39QzGPBvIoNEcC8toXvzPDXZ1B%2B05VonOuZjXh7lXjrPFvyxj%2BE35chlgQEeOMlpxEJjZFix2VT0sWxRe2%2BeHH5xszOsOi7z9OWroYGA4Gt7%2Bgix6k1lcte6nONKwjiKCiyir%2BGlmxVw1kl3V9Uc3r6SHlcXuhfwzTNOdEQQYx%2Fp%2B%2FrI%2BYgqJDnTLpVmedsyKjD1F4OY%2BW4xGFvO6Qq8i9bI5AfMJV%2FquVT7kcuLe78bYF7V%2Fs0gYwIFdv9lmeSQMzNKtxhbVpGdqv2%2BglATMA9IjrUc7IB%2FJaCe%2B04mqwfgiWnd1gjzYGkBzL049eglQ%3D%3D&ddkey=https%3Agb%2Fgroceries%2Fsainsburys-all-butter-croissant)

Pain Au Chocolat is sold at 80p [Link](https://www.sainsburys.co.uk/gol-ui/product/sainsburys--pain-au-chocolat)

Pain Au Raisins is sold at 80p [Link](https://www.sainsburys.co.uk/gol-ui/product/all-breakfast-bakery/sainsburys-pain-au-raisins)

At Allplants, the product option is usually selling in buddle. For prices, I would recommend we can price new products from the maximum of £4 to the minimum of £0.8 if a customer decide to add these treats to the product buddle.

# Thank you!
"""


